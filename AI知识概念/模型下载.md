### 下载 Hugging Face Hub CLI
pip3 install huggingface-hub


### 下载命令
```
huggingface-cli download \
  Rookie/Llama-3-8B-Instruct-Chinese \
  ggml-model-Q5_1.gguf \
  --local-dir ./ \
  --local-dir-use-symlinks False


huggingface-cli download \
  BAAI/bge-small-zh-v1.5 \
  --local-dir ./ \
  --local-dir-use-symlinks False


huggingface-cli download --resume-download --local-dir-use-symlinks False BAAI/bge-small-zh-v1.5 --local-dir bge-small-zh-v1.5



huggingface-cli download \
  Qwen/Qwen1.5-7B-Chat \
  --local-dir ./ \
  --local-dir-use-symlinks False


huggingface-cli download \
    openbmb/MiniCPM-Llama3-V-2_5-gguf \
    ggml-model-Q6_K.gguf \
    --local-dir ./ \
    --local-dir-use-symlinks False

huggingface-cli download \
    openbmb/MiniCPM-Llama3-V-2_5-gguf \
    mmproj-model-f16.gguf \
    --local-dir ./ \
    --local-dir-use-symlinks False


huggingface-cli download \
    microsoft/Florence-2-large \
    modeling_florence2.py \
    --local-dir ./ \
    --local-dir-use-symlinks False

huggingface-cli download \
    shenzhi-wang/Llama3-8B-Chinese-Chat-GGUF-8bit \
    Llama3-8B-Chinese-Chat-q8_0-v2_1.gguf \
    --local-dir ./ \
    --local-dir-use-symlinks False

huggingface-cli download \
    shenzhi-wang/Llama3-8B-Chinese-Chat-GGUF-4bit \
    Llama3-8B-Chinese-Chat-q4_0-v2_1.gguf \
    --local-dir ./ \
    --local-dir-use-symlinks False

huggingface-cli download \
    stabilityai/stable-diffusion-3-medium \
    sd3_medium.safetensors \
    --local-dir ./ \
    --local-dir-use-symlinks False

huggingface-cli download \
    --token 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 \
    stabilityai/stable-diffusion-3-medium \
    sd3_medium.safetensors \ 
    --local-dir ./ \
    --local-dir-use-symlinks False
```

### 导入 ollama

1. 创建 Modelfile  
FROM ./downloads/mistrallite.Q4_K_M.gguf

2. 创建 ollama 模型  
ollama create ModelName -f Modelfile

