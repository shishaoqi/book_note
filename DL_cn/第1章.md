### AI深度学习（deep learning）
针对这些比较直观的问题，本书讨论一种解决方案。该方案可以让计算机从经
验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简
单的概念之间的关系来定义。让计算机从经验获取知识，可以避免由人类来给计算
机形式化地指定它需要的所有知识。 ---- 层次化的概念让计算机构建较简单的概念来学
习复杂概念。如果绘制出这些概念如何建立在彼此之上的图，我们将得到一张 ‘‘深’’
（层次很多）的图。基于这个原因，我们称这种方法为 AI深度学习（deep learning）。

### 机器学习（machine learning）
依靠硬编码的知识体系面对的困难表明，AI 系统需要具备自己获取知识的能力，
即从原始数据中提取模式的能力。这种能力被称为 机器学习

引入机器学习使计算机能够解决涉及现实世界知识的问题，并能作出看似主观的决
策。比如，一个被称为 逻辑回归（logistic regression）的简单机器学习算法可以决定
是否建议剖腹产 (Mor-Yosef et al., 1990)。而同样是简单机器学习算法的 朴素贝叶
斯（naive Bayes）则可以区分垃圾电子邮件和合法电子邮件。---->  这些简单的机器学习算法的性能在很大程度上依赖于给定数据的 表示（representation）。

例如，当逻辑回归被用于判断产妇是否适合剖腹产时，AI 系统不会直接
检查患者。相反，医生需要告诉系统几条相关的信息，诸如是否存在子宫疤痕。表
示患者的每条信息被称为一个"特征"。逻辑回归学习病人的这些特征如何与各种结果
相关联。然而，它丝毫不能影响该特征定义的方式。如果将病人的 MRI 扫描作为逻
辑回归的输入，而不是医生正式的报告，它将无法作出有用的预测。MRI 扫描的单
一像素与分娩过程中并发症之间的相关性微乎其微。



表示的选择会对机器学习算法的性能产生巨大的影响



许多人工智能任务都可以通过以下方式解决：先提取一个合适的特征集，然后
将这些特征提供给简单的机器学习算法。


### 表示学习（representation learning）
对于许多任务来说，我们很难知道应该提取哪些特征。例如，假设我们想
编写一个程序来检测照片中的车。我们知道，汽车有轮子，所以我们可能会想用车
轮的存在与否作为特征。不幸的是，我们难以准确地根据像素值来描述车轮看上去
像什么。虽然车轮具有简单的几何形状，但它的图像可能会因场景而异，如落在车
轮上的阴影、太阳照亮的车轮的金属零件、汽车的挡泥板或者遮挡的车轮一部分的
前景物体等等。
    解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把表示映
射到输出。这种方法我们称之为 表示学习（representation learning）。学习到的表
示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预，就能让AI系
统迅速适应新的任务。表示学习算法只需几分钟就可以为简单的任务发现一个很好
的特征集，对于复杂任务则需要几小时到几个月。手动为一个复杂的任务设计特征
需要耗费大量的人工时间和精力；甚至需要花费整个社群研究人员几十年的时间。


### 解决表示学习中的核心问题
当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观
察数据的 变差因素（factors of variation）。在此背景下，‘‘因素’’ 这个词仅指代影响
的不同来源；因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。相
反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的
量。为了对观察到的数据提供有用的简化解释或推断其原因，它们还可能以概念的
形式存在于人类的思维中。它们可以被看作数据的概念或者抽象，帮助我们了解这
些数据的丰富多样性。当分析语音记录时，变差因素包括说话者的年龄、性别、他们
的口音和他们正在说的词语。当分析汽车的图像时，变差因素包括汽车的位置、它
的颜色、太阳的角度和亮度。
在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着我们能
够观察到的每一个数据。比如，在一张包含红色汽车的图片中，其单个像素在夜间
可能会非常接近黑色。汽车轮廓的形状取决于视角。大多数应用需要我们理清变差
因素并忽略我们不关心的因素。
显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话
口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这
几乎与获得原问题的表示一样困难，因此，乍一看，表示学习似乎并不能帮助我们。
深度学习（deep learning）通过其他较简单的表示来表达复杂表示，解决了表
示学习中的核心问题。