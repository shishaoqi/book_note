### AI深度学习（deep learning）
针对这些比较直观的问题，本书讨论一种解决方案。该方案可以让计算机从经
验中学习，并根据层次化的概念体系来理解世界，而每个概念则通过与某些相对简
单的概念之间的关系来定义。让计算机从经验获取知识，可以避免由人类来给计算
机形式化地指定它需要的所有知识。 ---- 层次化的概念让计算机构建较简单的概念来学
习复杂概念。如果绘制出这些概念如何建立在彼此之上的图，我们将得到一张 ‘‘深’’
（层次很多）的图。基于这个原因，我们称这种方法为 AI深度学习（deep learning）。

### 机器学习（machine learning）
依靠硬编码的知识体系面对的困难表明，AI 系统需要具备自己获取知识的能力，
即从原始数据中提取模式的能力。这种能力被称为 机器学习

引入机器学习使计算机能够解决涉及现实世界知识的问题，并能作出看似主观的决
策。比如，一个被称为 逻辑回归（logistic regression）的简单机器学习算法可以决定
是否建议剖腹产 (Mor-Yosef et al., 1990)。而同样是简单机器学习算法的 朴素贝叶
斯（naive Bayes）则可以区分垃圾电子邮件和合法电子邮件。---->  这些简单的机器学习算法的性能在很大程度上依赖于给定数据的 表示（representation）。

例如，当逻辑回归被用于判断产妇是否适合剖腹产时，AI 系统不会直接
检查患者。相反，医生需要告诉系统几条相关的信息，诸如是否存在子宫疤痕。表
示患者的每条信息被称为一个"特征"。逻辑回归学习病人的这些特征如何与各种结果
相关联。然而，它丝毫不能影响该特征定义的方式。如果将病人的 MRI 扫描作为逻
辑回归的输入，而不是医生正式的报告，它将无法作出有用的预测。MRI 扫描的单
一像素与分娩过程中并发症之间的相关性微乎其微。



表示的选择会对机器学习算法的性能产生巨大的影响



许多人工智能任务都可以通过以下方式解决：先提取一个合适的特征集，然后
将这些特征提供给简单的机器学习算法。


### 表示学习（representation learning）
对于许多任务来说，我们很难知道应该提取哪些特征。例如，假设我们想
编写一个程序来检测照片中的车。我们知道，汽车有轮子，所以我们可能会想用车
轮的存在与否作为特征。不幸的是，我们难以准确地根据像素值来描述车轮看上去
像什么。虽然车轮具有简单的几何形状，但它的图像可能会因场景而异，如落在车
轮上的阴影、太阳照亮的车轮的金属零件、汽车的挡泥板或者遮挡的车轮一部分的
前景物体等等。
    解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把表示映
射到输出。这种方法我们称之为 表示学习（representation learning）。学习到的表
示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预，就能让AI系
统迅速适应新的任务。表示学习算法只需几分钟就可以为简单的任务发现一个很好
的特征集，对于复杂任务则需要几小时到几个月。手动为一个复杂的任务设计特征
需要耗费大量的人工时间和精力；甚至需要花费整个社群研究人员几十年的时间。


### 解决表示学习中的核心问题
当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观
察数据的 变差因素（factors of variation）。在此背景下，‘‘因素’’ 这个词仅指代影响
的不同来源；因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。相
反，它们可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的
量。为了对观察到的数据提供有用的简化解释或推断其原因，它们还可能以概念的
形式存在于人类的思维中。它们可以被看作数据的概念或者抽象，帮助我们了解这
些数据的丰富多样性。当分析语音记录时，变差因素包括说话者的年龄、性别、他们
的口音和他们正在说的词语。当分析汽车的图像时，变差因素包括汽车的位置、它
的颜色、太阳的角度和亮度。
在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着我们能
够观察到的每一个数据。比如，在一张包含红色汽车的图片中，其单个像素在夜间
可能会非常接近黑色。汽车轮廓的形状取决于视角。大多数应用需要我们理清变差
因素并忽略我们不关心的因素。
显然，从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话
口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这
几乎与获得原问题的表示一样困难，因此，乍一看，表示学习似乎并不能帮助我们。
深度学习（deep learning）通过其他较简单的表示来表达复杂表示，解决了表
示学习中的核心问题。

深度学习让计算机通过较简单概念构建复杂的概念



这本书的主题——深度学习是通向人工智能的途径之一。具体来说，它
是机器学习的一种，一种能够使计算机系统从经验和数据中得到提高的技术。我们
坚信机器学习可以构建出在复杂实际环境下运行的 AI 系统

深度学习是一种特定类型的机器学习，具有强大的能力和灵活性，它将大千
世界表示为嵌套的层次概念体系（由较简单概念间的联系定义复杂概念、从一般抽
象概括到高级抽象表示）。



如今神经科学在深度学习研究中的作用被削弱，主要原因是我们根本没有足够
的关于大脑的信息来作为指导去使用它。要获得对被大脑实际使用算法的深刻理解，
我们需要有能力同时监测（至少是）数千相连神经元的活动。我们不能够做到这一
点，所以我们甚至连大脑最简单、最深入研究的部分都还远远没有理解 (Olshausen
and Field, 2005)。 ---- 现在GPU技术是否解决了这个问题？？？--> 是否已经有能力同时监测（至少是）数千相连神经元的活动 --- goLang 协程技术是否是一种代替？？




我们能够从神经科学得到一些粗略的指南。仅通过计算单元之间的相互作用而
变得智能的基本思想是受大脑启发的。新认知机 (Fukushima, 1980) 受哺乳动物视
觉系统的结构启发，引入了一个处理图片的强大模型架构，它后来成为了现代卷积
网络的基础 (LeCun et al., 1998c)（我们将会在第 9.10 节看到）。目前大多数神经网
络是基于一个称为 整流线性单元（rectified linear unit）的神经单元模型。原始认
知机 (Fukushima, 1975) 受我们关于大脑功能知识的启发，引入了一个更复杂的版
本。



值得注意的是，了解大脑是如何在算法层面上工作的尝试确实存在且发展良好。
这项尝试主要被称为 ‘‘计算神经科学’’，并且是独立于深度学习的领域。研究人员在
两个领域之间来回研究是很常见的。深度学习领域主要关注如何构建计算机系统，
从而成功解决需要智能才能解决的任务，而计算神经科学领域主要关注构建大脑如
何真实工作的比较精确的模型。



   联结主义的中心思想是，当网络将大量简单的计算单元连接在一起时可以实现
智能行为。这种见解同样适用于生物神经系统中的神经元，因为它和计算模型中隐
藏单元起着类似的作用。
   其中一个概念是 分布式表示（distributed representation）(Hinton et al., 1986)。
其思想是：系统的每一个输入都应该由多个特征表示，并且每一个特征都应该参与
到多个可能输入的表示。例如，假设我们有一个能够识别红色、绿色、或蓝色的汽
车、卡车和鸟类的视觉系统，表示这些输入的其中一个方法是将九个可能的组合：红
卡车，红汽车，红鸟，绿卡车等等使用单独的神经元或隐藏单元激活。这需要九个
不同的神经元，并且每个神经必须独立地学习颜色和对象身份的概念。改善这种情
况的方法之一是使用分布式表示，即用三个神经元描述颜色，三个神经元描述对象
身份。这仅仅需要 6 个神经元而不是 9 个，并且描述红色的神经元能够从汽车、卡
车和鸟类的图像中学习红色，而不仅仅是从一个特定类别的图像中学习。分布式表
示的概念是本书的核心，我们将在第十五章中更加详细地描述。（goLang语言的协程）



截至 2016 年，一个粗略的经验法则是，监督深度学习算法在
每类给定约 5000 个标注样本情况下一般将达到可以接受的性能，当至少有 1000 万
个标注样本的数据集用于训练时，它将达到或超过人类表现。



联结主义的
主要见解之一是，当动物的许多神经元一起工作时会变得聪明。单独神经元或小集
合的神经元不是特别有用。


### 技术突破了
自从隐藏单元引入以来，人工神经网络的规模大约每 2.4 年扩大一倍。这种增长是由
更大内存、更快的计算机和更大的可用数据集驱动的。更大的网络能够在更复杂的
任务中实现更高的精度。这种趋势看起来将持续数十年。除非有能力迅速扩展的新
技术，否则至少要到 21 世纪 50 年代，人工神经网络将才能具备与人脑相同数量级
的神经元。